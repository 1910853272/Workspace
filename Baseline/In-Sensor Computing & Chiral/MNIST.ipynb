{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T02:46:50.991710Z",
     "start_time": "2025-06-10T02:46:50.981223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n"
   ],
   "id": "3a271f3717706ea9",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T02:46:51.372638Z",
     "start_time": "2025-06-10T02:46:51.336807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 数据增强\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "transform_test = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# 下载与加载MNIST\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10000, shuffle=False,num_workers=0)\n"
   ],
   "id": "751abc9f6ec8dc4f",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T02:46:52.185394Z",
     "start_time": "2025-06-10T02:46:51.719172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_test_original, y_test_original = next(iter(test_loader))\n",
    "# x_test_original: [10000, 1, 28, 28], y_test_original: [10000]\n",
    "\n",
    "x_test_original = x_test_original.numpy()\n",
    "y_test_original = y_test_original.numpy()"
   ],
   "id": "7dd3aecc0b10bd9c",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "32e5a73433189b03",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 将两张图片中心对其然后叠加，能不能改成第二张图片右移10个像素点然后与第一张图片叠加，然后只保留第二张图像的28*28个像素点\n",
    "\n",
    "# 两张图片为同一张图片然后叠加"
   ],
   "id": "6607c5b60c0705b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T02:46:52.984009Z",
     "start_time": "2025-06-10T02:46:52.979205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_device_mixed_data(x_data, y_data, LH_param, RH_param, label_type='label1'):\n",
    "    n = x_data.shape[0]\n",
    "    mixed_images = []\n",
    "    mixed_labels = []\n",
    "    intensity_LH = 0.5\n",
    "    intensity_RH = 1 - intensity_LH\n",
    "    for i in range(n - 1):\n",
    "        img1, label1 = x_data[i], y_data[i]\n",
    "        img2, label2 = x_data[i + 1], y_data[i + 1]\n",
    "        mixed_img = img1 * LH_param * intensity_LH + img2 * RH_param * intensity_RH\n",
    "        mixed_img = mixed_img / np.max(mixed_img)\n",
    "        mixed_images.append(mixed_img)\n",
    "        mixed_labels.append(label1 if label_type == 'label1' else label2)\n",
    "    # 最后一张和第一张混合\n",
    "    img1, label1 = x_data[-1], y_data[-1]\n",
    "    img2, label2 = x_data[0], y_data[0]\n",
    "    mixed_img = img1 * LH_param * intensity_LH + img2 * RH_param * intensity_RH\n",
    "    mixed_img = mixed_img / np.max(mixed_img)\n",
    "    mixed_images.append(mixed_img)\n",
    "    mixed_labels.append(label1 if label_type == 'label1' else label2)\n",
    "    mixed_images = np.stack(mixed_images)\n",
    "    mixed_labels = np.array(mixed_labels)\n",
    "    return mixed_images, mixed_labels\n"
   ],
   "id": "11692455cd7f020c",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T02:48:11.082698Z",
     "start_time": "2025-06-10T02:48:10.818162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "R_form_LH = 0.7\n",
    "R_form_RH = 0.3\n",
    "S_form_LH = 0.4\n",
    "S_form_RH = 0.6\n",
    "\n",
    "x_test_mixed, y_test_mixed = create_device_mixed_data(x_test_original, y_test_original, 1.0, 1.0, label_type='label1')\n",
    "x_test_R_form, y_test_R_form = create_device_mixed_data(x_test_original, y_test_original, R_form_LH, R_form_RH, label_type='label1')\n",
    "x_test_S_form, y_test_S_form = create_device_mixed_data(x_test_original, y_test_original, S_form_LH, S_form_RH, label_type='label2')\n"
   ],
   "id": "91a058e8a5b659de",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T02:48:11.590423Z",
     "start_time": "2025-06-10T02:48:11.395076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "idx = np.random.randint(0, x_test_original.shape[0])\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(12, 4))\n",
    "plt.suptitle(f'Index {idx}: Original/Mixed/R-form/S-form')\n",
    "\n",
    "axs[0].imshow(x_test_original[idx][0], cmap='gray')\n",
    "axs[0].set_title(f'Original\\nlabel={y_test_original[idx]}')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(x_test_mixed[idx][0], cmap='gray')\n",
    "axs[1].set_title(f'Mixed\\nlabel={y_test_mixed[idx]}')\n",
    "axs[1].axis('off')\n",
    "\n",
    "axs[2].imshow(x_test_R_form[idx][0], cmap='gray')\n",
    "axs[2].set_title(f'R-form\\nlabel={y_test_R_form[idx]}')\n",
    "axs[2].axis('off')\n",
    "\n",
    "axs[3].imshow(x_test_S_form[idx][0], cmap='gray')\n",
    "axs[3].set_title(f'S-form\\nlabel={y_test_S_form[idx]}')\n",
    "axs[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "4ae9a30a3a4645cb",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T02:48:13.217444Z",
     "start_time": "2025-06-10T02:48:13.190676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(256),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*3*3, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n"
   ],
   "id": "2f27fb498540b1d4",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T02:48:14.005401Z",
     "start_time": "2025-06-10T02:48:13.987371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=2e-6)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "665e50b57af4ec18",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T02:48:14.668178Z",
     "start_time": "2025-06-10T02:48:14.658141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_mixed_loader(x, y, batch_size=64):\n",
    "    x_tensor = torch.FloatTensor(x)\n",
    "    y_tensor = torch.LongTensor(y)\n",
    "    dataset = TensorDataset(x_tensor, y_tensor)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False,num_workers=0)"
   ],
   "id": "6421b56097c8b9d0",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T02:51:41.200308Z",
     "start_time": "2025-06-10T02:48:16.364894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.makedirs('results', exist_ok=True)\n",
    "epochs = 20\n",
    "accuracy_data = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 评估\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        def eval_on(loader, true_labels=None):\n",
    "            preds = []\n",
    "            trues = []\n",
    "            for images, labels in loader:\n",
    "                images = images.to(device)\n",
    "                out = model(images)\n",
    "                pred = torch.argmax(out, 1).cpu().numpy()\n",
    "                preds.append(pred)\n",
    "                if true_labels is not None:\n",
    "                    trues.append(labels.numpy())\n",
    "            return np.concatenate(preds), np.concatenate(trues) if true_labels is not None else None\n",
    "\n",
    "        # 原始\n",
    "        preds_ori, _ = eval_on(test_loader, True)\n",
    "        acc_ori = np.mean(preds_ori == y_test_original)\n",
    "        # 普通混合\n",
    "        loader_mixed = get_mixed_loader(x_test_mixed, y_test_mixed)\n",
    "        preds_mixed, _ = eval_on(loader_mixed, True)\n",
    "        acc_mixed = np.mean(preds_mixed == y_test_mixed)\n",
    "        # R-form\n",
    "        loader_R = get_mixed_loader(x_test_R_form, y_test_R_form)\n",
    "        preds_R, _ = eval_on(loader_R, True)\n",
    "        acc_R = np.mean(preds_R == y_test_R_form)\n",
    "        # S-form\n",
    "        loader_S = get_mixed_loader(x_test_S_form, y_test_S_form)\n",
    "        preds_S, _ = eval_on(loader_S, True)\n",
    "        acc_S = np.mean(preds_S == y_test_S_form)\n",
    "\n",
    "    accuracy_data.append([epoch+1, acc_ori, acc_mixed, acc_R, acc_S])\n",
    "    print(f\"Epoch {epoch+1}: 原始 {acc_ori:.4f}, 普通混合 {acc_mixed:.4f}, R-form {acc_R:.4f}, S-form {acc_S:.4f}\")\n",
    "\n",
    "accuracy_data = np.array(accuracy_data)\n",
    "np.savetxt('results/MNIST_accuracy_data_pytorch.csv', accuracy_data, fmt='%1.4f', delimiter=',')\n"
   ],
   "id": "95d40eb696732797",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T02:51:47.288330Z",
     "start_time": "2025-06-10T02:51:46.907081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_confusion_matrix_pytorch(y_true, y_pred, filename_image, filename_data):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(cm, square=True, annot=False, fmt='d', cbar=False, cmap=plt.cm.Blues)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.savefig(filename_image)\n",
    "    plt.close()\n",
    "    np.savetxt(filename_data, cm, fmt='%d', delimiter=',')\n",
    "\n",
    "# 最后一轮的预测结果\n",
    "save_confusion_matrix_pytorch(y_test_original, preds_ori, 'results/MNIST_confusion_matrix_original_pytorch.png',\n",
    "                              'results/MNIST_confusion_matrix_original_pytorch.csv')\n",
    "save_confusion_matrix_pytorch(y_test_mixed, preds_mixed, 'results/MNIST_confusion_matrix_mixed_pytorch.png',\n",
    "                              'results/MNIST_confusion_matrix_mixed_pytorch.csv')\n",
    "save_confusion_matrix_pytorch(y_test_R_form, preds_R, 'results/MNIST_confusion_matrix_R_form_pytorch.png',\n",
    "                              'results/MNIST_confusion_matrix_R_form_pytorch.csv')\n",
    "save_confusion_matrix_pytorch(y_test_S_form, preds_S, 'results/MNIST_confusion_matrix_S_form_pytorch.png',\n",
    "                              'results/MNIST_confusion_matrix_S_form_pytorch.csv')\n"
   ],
   "id": "2507839365126eaf",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "50b737bd375b7570",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

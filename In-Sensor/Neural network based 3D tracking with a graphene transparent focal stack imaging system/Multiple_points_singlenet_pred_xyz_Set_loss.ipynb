{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Version for Multiple obj points (2 or 3) and multiple shifts (1, 2 or 3 now)\n",
    "##### To run: chose proper os.chdir and data_path. chose proper input_dim, and note other hyper settings. Chose desired relative_pos_list. Rest doesn't need to change necessarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split,Subset\n",
    "from torch.nn.parameter import Parameter\n",
    "from logger import Logger\n",
    "import os\n",
    "from utils_twopoints import *\n",
    "from visualize import show2D_2objs, show2D_3objs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "torch.backends.cudnn.deterministic=True\n",
    "\n",
    "plt.rcParams.update({'font.size': 15,'lines.markersize':10})\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(190)\n",
    "torch.manual_seed(120) ##set the random seed so when construct the \n",
    "\n",
    "#os.chdir('E:/Academic/MATLAB/Dehui_FS/2018_11_03 data')\n",
    "#os.chdir('E:/Academic/MATLAB/Dehui_FS/2018_11_21 CCD XYZ sweep')\n",
    "#data_path='FS_LD9by9_All_CCD sweep xyz_avg_win1_normalizedbymax'\n",
    "\n",
    "os.chdir('/home/zyhuang/WD/Net3D/2018_11_03 data/')\n",
    "data_path='18_11_03sweepxyz_normalizedbymax'\n",
    "        \n",
    "scale_z=True #divide z coord by 33.3 to make it has same range as x,y\n",
    "lr=1e-3\n",
    "num_epoch=2000\n",
    "logfreq=10\n",
    "bs_test_percentage = 0.15\n",
    "bs_train=100#remaining used as trainset\n",
    "num_features=64\n",
    "#input_dim=4*4*2\n",
    "input_dim=4*4*2\n",
    "nx,ny,nz=11,11,11\n",
    "\n",
    "#relative_pos_list=[[(0,0,0),(1,2,3)]] # for two objs, single shift\n",
    "relative_pos_list=[[(0,0,1),(0,3,0)],[(0,1,3),(2,1,1)]] # for two objs, two shift\n",
    "#relative_pos_list=[[(0,0,1),(0,3,0)],[(0,1,3),(2,1,1)],[(1,3,2),(0,1,1)]] #for two objs, three shifts\n",
    "#relative_pos_list=[[(0,0,1),(0,3,0),(1,0,2)],[(0,1,3),(2,1,1),(3,3,2)]] # for three objs, two shift\n",
    "#relative_pos_list=[[(0,0,1),(0,3,0),(1,0,2)],[(0,1,3),(2,1,1),(3,3,2)],[(3,2,2),(0,2,1),(3,0,2)]] # for three objs, three shift\n",
    "Nshift=len(relative_pos_list)\n",
    "Nobj=len(relative_pos_list[0])\n",
    "Nobj_eng={'2':'two','3':'three'}\n",
    "\n",
    "if Nshift==1:\n",
    "    relative_pos=relative_pos_list[0]\n",
    "    ds_Full=globals()['FSdataset_'+Nobj_eng[str(Nobj)]+'points_v2'](data_path,relative_pos=relative_pos,nx=nx,ny=ny,nz=nz,scale_z=scale_z)\n",
    "    bs_test = round(bs_test_percentage * len(ds_Full))\n",
    "    save_name=str(Nobj)+'_objs_singlenetxyz_Set_loss_1shift_scale_z_'+str(scale_z)+'/'+\"\".join([s for s in str(relative_pos) if s.isdigit()])+'/depthnet4_Nobj_xyz('+str(num_features)+'features)'\\\n",
    "    +'_adam_lr_'+str(lr)+'_bs_train_'+str(bs_train)+'_bs_test_'+str(bs_test)+'_numepoch_'+str(num_epoch)\n",
    "else:\n",
    "    ds_Full=globals()['FSdataset_'+Nobj_eng[str(Nobj)]+'points_multipleshifts_v2'](data_path,relative_pos_list=relative_pos_list,nx=nx,ny=ny,nz=nz,scale_z=scale_z)\n",
    "    bs_test = round(bs_test_percentage * len(ds_Full))\n",
    "    save_name=str(Nobj)+'_objs_singlenetxyz_Set_loss_'+str(Nshift)+'shifts_scale_z_'+str(scale_z)+'/'+\"\".join([s for s in str(relative_pos_list) if s.isdigit()])\\\n",
    "    +'/depthnet4_Nobj_xyz('+str(num_features)+'features)'+'_adam_lr_'+str(lr)+'_bs_train_'+str(bs_train)+'_bs_test_'+str(bs_test)+'_numepoch_'+str(num_epoch)\n",
    "print(\"Length of Full dataset is %s\" %len(ds_Full))\n",
    "\n",
    "ds_train,ds_test=random_split(ds_Full, [len(ds_Full)-bs_test,bs_test])   \n",
    "train_loader=DataLoader(ds_train, batch_size=bs_train,shuffle=True)\n",
    "test_loader=DataLoader(ds_test, batch_size=bs_test,shuffle=False)\n",
    "\n",
    "logger = Logger('./logs_paper_data/'+ save_name) ##set the logger for tensorboard and save the log file to ./logs/Adam \n",
    "#dtype = torch.FloatTensor ##run on cpu\n",
    "dtype = torch.cuda.FloatTensor \n",
    "\n",
    "net=depthnet4_Nobj_xyz(input_dim,num_features,Nobj=Nobj)\n",
    "net.type(dtype)\n",
    "\n",
    "#criterion=torch.nn.L1Loss()\n",
    "if Nobj == 2:\n",
    "    criterion=Set_loss_2obj()   \n",
    "elif Nobj == 3:\n",
    "    criterion=Set_loss_3obj()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history=[]\n",
    "test_loss_history=[]\n",
    "for epoch in range(num_epoch):\n",
    "    if np.mod(epoch,logfreq)==0: \n",
    "        print(\"Current epoch number%d\" %epoch) \n",
    "    for idx,data in enumerate(train_loader,0):\n",
    "        net.train()\n",
    "        if Nobj == 2:\n",
    "            FS_bat,xyz1_true,xyz2_true=Variable(data['FS'].type(dtype)),Variable(data['xyz'][:,0:3].type(dtype)),Variable(data['xyz'][:,3:6].type(dtype))\n",
    "            xyz1_pred,xyz2_pred=net(FS_bat)[:,0:3],net(FS_bat)[:,3:6]\n",
    "            loss=criterion(xyz1_pred,xyz2_pred,xyz1_true,xyz2_true)\n",
    "        elif Nobj == 3:\n",
    "            FS_bat,xyz1_true,xyz2_true,xyz3_true=Variable(data['FS'].type(dtype)),Variable(data['xyz'][:,0:3].type(dtype)),Variable(data['xyz'][:,3:6].type(dtype)),Variable(data['xyz'][:,6:9].type(dtype))\n",
    "            xyz1_pred,xyz2_pred,xyz3_pred=net(FS_bat)[:,0:3],net(FS_bat)[:,3:6],net(FS_bat)[:,6:9]\n",
    "            loss=criterion(xyz1_pred,xyz2_pred,xyz3_pred,xyz1_true,xyz2_true,xyz3_true)            \n",
    "        loss_history.append(loss.data[0])\n",
    "        if np.mod(epoch,logfreq)==0: \n",
    "            print('loss is %3f'%(loss.data[0]))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if np.mod(epoch,logfreq)==0:  \n",
    "        net.eval()\n",
    "        data=next(iter(test_loader))\n",
    "        if Nobj ==2:\n",
    "            FS_bat,xyz1_true,xyz2_true=Variable(data['FS'].type(dtype)),Variable(data['xyz'][:,0:3].type(dtype)),Variable(data['xyz'][:,3:6].type(dtype))\n",
    "            xyz1_pred,xyz2_pred=net(FS_bat)[:,0:3],net(FS_bat)[:,3:6]\n",
    "            test_loss=criterion(xyz1_pred,xyz2_pred,xyz1_true,xyz2_true)\n",
    "        elif Nobj ==3:\n",
    "            FS_bat,xyz1_true,xyz2_true,xyz3_true=Variable(data['FS'].type(dtype)),Variable(data['xyz'][:,0:3].type(dtype)),Variable(data['xyz'][:,3:6].type(dtype)),Variable(data['xyz'][:,6:9].type(dtype))\n",
    "            xyz1_pred,xyz2_pred,xyz3_pred=net(FS_bat)[:,0:3],net(FS_bat)[:,3:6],net(FS_bat)[:,6:9]\n",
    "            test_loss=criterion(xyz1_pred,xyz2_pred,xyz3_pred,xyz1_true,xyz2_true,xyz3_true)\n",
    "            \n",
    "        test_loss_history.append(test_loss.data[0])       \n",
    "        print('Test Loss is %3f' %(test_loss.data[0]))#for multiple test sample\n",
    "        \n",
    "        step=epoch+1\n",
    "        info = {\n",
    "        'training_loss': loss.data[0],\n",
    "        'val_loss':test_loss.data[0],\n",
    "        }\n",
    "        for tag, value in info.items():\n",
    "            logger.scalar_summary(tag, value, step+1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(loss_history[::len(train_loader)],label='training_loss')#training_loss\n",
    "plt.legend()\n",
    "plt.title('Training loss vs epoch number')\n",
    "plt.savefig('logs_paper_data/'+save_name+'/Training loss')\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(0,epoch,logfreq),test_loss_history[:],label='test_loss')\n",
    "plt.legend()\n",
    "plt.title('Test loss vs epoch number')\n",
    "plt.savefig('logs_paper_data/'+save_name+'/Test loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this part of code is added , previsouly the test loss is not the final model test loss since np.mod(epoch,logfreq)==0 is false for last epoch \n",
    "net.eval()\n",
    "\n",
    "data=next(iter(test_loader))\n",
    "if Nobj ==2:\n",
    "    FS_bat,xyz1_true,xyz2_true=Variable(data['FS'].type(dtype)),Variable(data['xyz'][:,0:3].type(dtype)),Variable(data['xyz'][:,3:6].type(dtype))\n",
    "    xyz1_pred,xyz2_pred=net(FS_bat)[:,0:3],net(FS_bat)[:,3:6]\n",
    "    test_loss=criterion(xyz1_pred,xyz2_pred,xyz1_true,xyz2_true)\n",
    "elif Nobj ==3:\n",
    "    FS_bat,xyz1_true,xyz2_true,xyz3_true=Variable(data['FS'].type(dtype)),Variable(data['xyz'][:,0:3].type(dtype)),Variable(data['xyz'][:,3:6].type(dtype)),Variable(data['xyz'][:,6:9].type(dtype))\n",
    "    xyz1_pred,xyz2_pred,xyz3_pred=net(FS_bat)[:,0:3],net(FS_bat)[:,3:6],net(FS_bat)[:,6:9]\n",
    "    test_loss=criterion(xyz1_pred,xyz2_pred,xyz3_pred,xyz1_true,xyz2_true,xyz3_true)\n",
    "text_file = open('logs_paper_data/'+save_name+\"/Loss_final.txt\", \"w\")\n",
    "text_file.write('loss is %.4f(%.3f mm)\\n'%(loss.data[0],np.sqrt(loss.data[0])))\n",
    "text_file.write('Test Loss is %.4f(%.3f mm).' %(test_loss.data[0],np.sqrt(test_loss.data[0])))\n",
    "text_file.close()\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bat=next(iter(test_loader))\n",
    "FS_bat,trueXYZobjs_bat=test_bat['FS'],test_bat['xyz'][:,:]\n",
    "#predXYZobjs_bat=torch.cat((net_x(Variable(FS_bat.type(dtype))),net_y(Variable(FS_bat.type(dtype))),net_z(Variable(FS_bat.type(dtype)))),dim=1).data.cpu()[:,[0,2,4,1,3,5]]\n",
    "predXYZobjs_bat=net(Variable(FS_bat).type(dtype)).data.cpu()\n",
    "\n",
    "#scale back the z coordinates\n",
    "if Nobj == 2:\n",
    "    predXYZobjs_bat[:,[2,5]] = predXYZobjs_bat[:,[2,5]]*33.3\n",
    "    trueXYZobjs_bat[:,[2,5]] = trueXYZobjs_bat[:,[2,5]]*33.3\n",
    "elif Nobj == 3:\n",
    "    predXYZobjs_bat[:,[2,5,8]] = predXYZobjs_bat[:,[2,5,8]]*33.3\n",
    "    trueXYZobjs_bat[:,[2,5,8]] = trueXYZobjs_bat[:,[2,5,8]]*33.3\n",
    "\n",
    "print(predXYZobjs_bat)\n",
    "print(trueXYZobjs_bat)\n",
    "\n",
    "globals()['show2D_'+str(Nobj)+'objs'](trueXYZobjs_bat,predXYZobjs_bat,howmany=10,save_name='logs_paper_data/'+save_name+'/2Ds')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), os.path.join('logs_paper_data',save_name, 'model.pth'))\n",
    "#Saving test data as .mat\n",
    "from scipy import io\n",
    "data={'trueXYZ':trueXYZobjs_bat.cpu().numpy(), 'PredictedXYZ':predXYZobjs_bat.cpu().numpy()}\n",
    "io.savemat('logs_paper_data/'+save_name+\"/testData.mat\",data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify Test set and train set are not overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(ds_train, batch_size=710,shuffle=False)\n",
    "test_loader=DataLoader(ds_test, batch_size=10,shuffle=False)\n",
    "next(iter(train_loader))['xyz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test if train/test overlap\n",
    "bs_test=300 #specify test set size\n",
    "bs_train=720-bs_test#remaining used as trainset\n",
    "ds_Full=FSdataset_twopoints('18_11_03sweepxyz.mat',dx=1,dy=2,dz=3,nx=11,ny=11,nz=11)\n",
    "ds_train,ds_test=random_split(ds_Full, [len(ds_Full)-bs_test,bs_test])   \n",
    "train_loader=DataLoader(ds_train, batch_size=bs_train,shuffle=False)\n",
    "test_loader=DataLoader(ds_test, batch_size=bs_test,shuffle=False)\n",
    "next(iter(train_loader))['xyz']\n",
    "((next(iter(test_loader))['xyz'][9]==next(iter(train_loader))['xyz']).sum(dim=1)==6).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

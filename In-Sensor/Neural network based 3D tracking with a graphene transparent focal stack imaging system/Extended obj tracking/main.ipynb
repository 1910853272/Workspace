{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version loading each image separately, suitable for new synced camera capture data and large data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset as dset\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import ConcatDataset,DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from tensorboardX import SummaryWriter\n",
    "from model import vgg,vgg_bn,vgg_DDFF,vgg_DDFF_bn\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_utils import show2D\n",
    "\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "np.random.seed(100);\n",
    "torch.manual_seed(100);\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import adjust_gamma\n",
    "class RandomGamma(object):\n",
    "    \"\"\"\n",
    "    Crop the given PIL Image at a random location.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gammaRange = [0.5,1],gainRange = [0.5,1.5]):\n",
    "            self.gammaMin,self.gammaMax = gammaRange[0],gammaRange[1]\n",
    "            self.gainMin,self.gainMax = gainRange[0],gainRange[1]\n",
    "    @staticmethod\n",
    "    def get_params(gammaMin,gammaMax,gainMin,gainMax):\n",
    "        gamma = np.random.rand()*(gammaMax-gammaMin)+gammaMin\n",
    "        gain =  np.random.rand()*(gainMax-gainMin)+gainMin\n",
    "        return gamma,gain\n",
    "\n",
    "    def __call__(self, PILimg):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): PIL RGB image in range [0,255]\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: gamma augmentated PIL image in range [0,255*gain]\n",
    "        \"\"\"\n",
    "\n",
    "        gamma,gain = self.get_params(self.gammaMin, self.gammaMax, self.gainMin, self.gainMax)\n",
    "        print(gamma)\n",
    "        print(gain)\n",
    "        return adjust_gamma(PILimg, gamma, gain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSdataset_PIL(dset):\n",
    "    \"\"\"\n",
    "    Creating FS dataset (for one orientation) containing two matrix, FS and xyzthetaphi. FS has dimension N,nF,H(y),W(x), xyz has dimension N,5. Where 5 columns are coordinates of object x,y,z,theta,phi respectively. The N should increase along x first, then y, then z. \n",
    "    and support  a dictionary containing FS (N,nF,H,W) and xyzthetaphi (N,5), i.e.,(x1,y1,z1,theta,phi)   \n",
    "    \"\"\"\n",
    "    def __init__(self,datafolder,F_list=[''], orientation='', thetaphi=np.zeros(1), nx = 4, ny = 4, nz = 9, constant_brightness = False, gamma_aug = False):\n",
    "        #data folder: path to the folde rcontaining all subdirectories of all F and all orientation\n",
    "        #F_list: list of strings speifying value of sensor position F, in the order of increasing distance (F) from the camera e.g F_list = ['F40','F41']\n",
    "        #orientation: string specifying the orientation of the object, e.g. 'o1'\n",
    "        # thetaphi: the encoding of the thetaphi for the orientation, should be size (nx*ny*nz,2)\n",
    "        super(FSdataset_PIL,self).__init__()\n",
    "        self.datafolder, self.F_list, self.orientation = datafolder, F_list, orientation\n",
    "        self.N = nx*ny*nz\n",
    "        self.XYZthetaphi = np.concatenate([self._generate_XYZ(nx,ny,nz),thetaphi], 1).astype('float32') #generate XYZ and concatenate with thetaphi\n",
    "        self.transform = self._make_transform(constant_brightness = constant_brightness, gamma_aug = gamma_aug)\n",
    "    def __len__(self):\n",
    "        length_list = [len(os.listdir(os.path.join(self.datafolder, F +'_'+self.orientation))) for F in self.F_list]\n",
    "        assert all(length == self.N for length in length_list), \"Number of images for each F is not all the same!\" #check if number of images for each F is the same\n",
    "        return self.N # number of images of each F, i.e., number of object positions\n",
    "    def __getitem__(self,index):\n",
    "        #load images in PIL Image format into a list\n",
    "        FS = [Image.open(os.path.join(self.datafolder, F +'_'+self.orientation,'%04d.bmp' %(index+1))) for F in self.F_list] #color image list, +1 since the proper labview saved image starts at index 1\n",
    "        FS = [self.transform(img) for img in FS]\n",
    "        #FS = [img.convert('L') for img in FS]\n",
    "        #FS = [self.PIL2tensor(img) for img in FS]\n",
    "        FS = torch.cat(FS, 0) # concatenate tensors in color dimension\n",
    "        return {'FS':FS,'xyzthetaphi':self.XYZthetaphi[index]} #FS has dimension nF,H(1024),W(1280), xyz has shape (5,),i.e., (x,y,z,theta,phi)\n",
    "    @classmethod\n",
    "    def _make_transform(cls, constant_brightness = False, gamma_aug = False):\n",
    "        #generate the transform needed when loading the image\n",
    "        if constant_brightness == False and gamma_aug == False:\n",
    "            T_list = [T.Lambda(cls.convert2gray), T.ToTensor()] #  oTensor convert H,W,C PIL images to torch float tensor C(1),H,W normalized to range [0,1]. Image.convert('L') convert to gray PIL images, assume color channel in RGB order\n",
    "            \n",
    "        elif constant_brightness == False and gamma_aug == True:\n",
    "            T_list = [RandomGamma(), T.Lambda(cls.convert2gray), T.ToTensor()]\n",
    "        elif constant_brightness == True and gamma_aug == False:\n",
    "            T_list = [T.Lambda(cls.convert2gray), T.ToTensor(), T.Lambda(cls.norm_const_bright)]\n",
    "        else: # Both true\n",
    "            T_list = [RandomGamma(), T.Lambda(cls.convert2gray), T.ToTensor(), T.Lambda(cls.norm_const_bright)]\n",
    "        return T.Compose(T_list)\n",
    "    @staticmethod\n",
    "    def convert2gray(img):\n",
    "        #input: PIL image\n",
    "        #ouput gray scale PIL image \n",
    "        return img.convert('L')\n",
    "    @staticmethod\n",
    "    def norm_const_bright(img):\n",
    "        #input 2D img torch tensor;output image with mean intensity const_value\n",
    "        const_value = 0.5\n",
    "        return img/img.mean()*const_value\n",
    "    @staticmethod\n",
    "    def _generate_XYZ(nx,ny,nz):\n",
    "        # auxilary function for generating XYZ, return nx*ny*nz,3\n",
    "        x = np.linspace(0, 1, nx)\n",
    "        y = np.linspace(0, 1, ny)\n",
    "        z = np.linspace(0, 1, nz)\n",
    "        X, Y, Z = np.meshgrid(x, y, z, indexing = 'ij')     \n",
    "        return np.concatenate([X.flatten(order = 'F')[:,np.newaxis],Y.flatten(order = 'F')[:,np.newaxis],Z.flatten(order = 'F')[:,np.newaxis]], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total # of data sample is 288\n",
    "#valds_size=43\n",
    "valds_size=2300\n",
    "bs_train=20\n",
    "bs_val=10\n",
    "lr=1e-4\n",
    "#writer = SummaryWriter('logs/3 20 data_norm_imag_c_0.5/D_4_DDFF_bn/lr1e-3_valds_20_o1_o2')\n",
    "#writer = SummaryWriter('logs/3 20 data/D_4_DDFF_bn/lr1e-3_valds_20_o1_o2')\n",
    "#log_path = 'logs/6 13 data/D_4_DDFF_bn_no_dropout/lr1e-4_bs10_valds_40_o1_o2_o3_100hiddenUnits_sensors_F45'\n",
    "#log_path = 'logs/orientation_classification/5 20 data/D_4_bn_no_dropout/lr1e-4_bs20_valds_580_o1_o2_o3_100hiddenUnits'\n",
    "#log_path = 'logs/07 08 data/D_4_DDFF_bn_no_dropout/lr1e-4_bs20_valds_2300_train_o1_to_o7_val_o8_100hiddenUnits'\n",
    "log_path = 'logs/orientation_classification/7 08 data/D_4_DDFF_bn_no_dropout/lr1e-4_gamma_0.3_stepAt_3_5_10_20_bs20_valds_2300_o1_to_o8_100hiddenUnits_run3'\n",
    "writer =  SummaryWriter(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nx,ny,nz = [11,11,16]\n",
    "constant_brightness = False\n",
    "gamma_aug = False\n",
    "datafolder = '/home/zyhuang/EVO970Plus/2019 07 08/'\n",
    "#datafolder = '/home/zyhuang/WD/XYZthetaphi/Raw Camera data/2019 06 13/'\n",
    "F_list = ['F35.95','F37.35']\n",
    "ds1=FSdataset_PIL(datafolder,F_list=F_list, orientation = 'o1', thetaphi = 0*np.ones([nx*ny*nz,2]), nx = nx, ny = ny, nz = nz, constant_brightness = constant_brightness, gamma_aug = gamma_aug)\n",
    "ds2=FSdataset_PIL(datafolder,F_list=F_list, orientation = 'o2', thetaphi = 1*np.ones([nx*ny*nz,2]), nx = nx, ny = ny, nz = nz, constant_brightness = constant_brightness, gamma_aug = gamma_aug)    \n",
    "ds3=FSdataset_PIL(datafolder,F_list=F_list, orientation = 'o3', thetaphi = 2*np.ones([nx*ny*nz,2]), nx = nx, ny = ny, nz = nz, constant_brightness = constant_brightness, gamma_aug = gamma_aug)        \n",
    "\n",
    "ds4=FSdataset_PIL(datafolder,F_list=F_list, orientation = 'o4', thetaphi = 3*np.ones([nx*ny*nz,2]), nx = nx, ny = ny, nz = nz, constant_brightness = constant_brightness, gamma_aug = gamma_aug)    \n",
    "ds5=FSdataset_PIL(datafolder,F_list=F_list, orientation = 'o5', thetaphi = 4*np.ones([nx*ny*nz,2]), nx = nx, ny = ny, nz = nz, constant_brightness = constant_brightness, gamma_aug = gamma_aug)    \n",
    "ds6=FSdataset_PIL(datafolder,F_list=F_list, orientation = 'o6', thetaphi = 5*np.ones([nx*ny*nz,2]), nx = nx, ny = ny, nz = nz, constant_brightness = constant_brightness, gamma_aug = gamma_aug)    \n",
    "ds7=FSdataset_PIL(datafolder,F_list=F_list, orientation = 'o7', thetaphi = 6*np.ones([nx*ny*nz,2]), nx = nx, ny = ny, nz = nz, constant_brightness = constant_brightness, gamma_aug = gamma_aug)    \n",
    "ds8=FSdataset_PIL(datafolder,F_list=F_list, orientation = 'o8', thetaphi = 7*np.ones([nx*ny*nz,2]), nx = nx, ny = ny, nz = nz, constant_brightness = constant_brightness, gamma_aug = gamma_aug)    \n",
    "\n",
    "ds_all=ConcatDataset([ds1,ds2,ds3,ds4,ds5,ds6,ds7,ds8])\n",
    "\n",
    "ds_train,ds_val=random_split(ds_all, [len(ds_all)-valds_size,valds_size])\n",
    "\n",
    "train_loader=DataLoader(ds_train, batch_size=bs_train,shuffle=True, num_workers = 4)\n",
    "val_loader=DataLoader(ds_val, batch_size=bs_val,shuffle=False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training code for predicting xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "#net=vgg_bn(config_key='A_4')\n",
    "#net=vgg(config_key='D_4')\n",
    "net=vgg_DDFF_bn(nF=len(F_list),config_key='D_4_DDFF',dropout = False, num_hiddenunit=100)\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer=optim.Adam(net.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "step=0\n",
    "for epoch in range(60):\n",
    "    print(\"Current epoch number%d\" %epoch) \n",
    "    for idx,data in enumerate(train_loader,0):\n",
    "        net.train()\n",
    "        FS,xyz,theta,phi=data['FS'].to(device),data['xyzthetaphi'][:,0:3].to(device),data['xyzthetaphi'][:,3].to(device),data['xyzthetaphi'][:,4].to(device)\n",
    "        score=net(FS)\n",
    "        loss=criterion(score,xyz)\n",
    "        loss_x,loss_y,loss_z=criterion(score[:,0],xyz[:,0]),criterion(score[:,1],xyz[:,1]),criterion(score[:,2],xyz[:,2])\n",
    "        print('Loss is %3f' %(loss.item()))\n",
    "        print('Loss x,y,z is %3f, %3f, %3f' %(loss_x.item(),loss_y.item(),loss_z.item()))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()            \n",
    "        optimizer.step() \n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            writer.add_scalar('loss', loss.item(), step)\n",
    "            writer.add_scalar('loss z', loss_z.item(), step)\n",
    "        \n",
    "        step = step + 1 \n",
    "    \n",
    "    #validate every epoch\n",
    "    full_val_loss,full_val_loss_x,full_val_loss_y,full_val_loss_z = [0,0,0,0]\n",
    "    net.eval()\n",
    "    for idx,data in enumerate(val_loader,0):\n",
    "        FS,xyz,theta,phi=data['FS'].to(device),data['xyzthetaphi'][:,0:3].to(device),data['xyzthetaphi'][:,3].to(device),data['xyzthetaphi'][:,4].to(device)\n",
    "        with torch.no_grad():\n",
    "            score=net(FS)\n",
    "            loss=criterion(score,xyz)\n",
    "            loss_x,loss_y,loss_z=criterion(score[:,0],xyz[:,0]),criterion(score[:,1],xyz[:,1]),criterion(score[:,2],xyz[:,2])\n",
    "            full_val_loss += loss.item()/len(val_loader)\n",
    "            full_val_loss_x += loss_x.item()/len(val_loader)\n",
    "            full_val_loss_y += loss_y.item()/len(val_loader)\n",
    "            full_val_loss_z += loss_z.item()/len(val_loader)\n",
    "\n",
    "    print('Val Loss is %3f' %(full_val_loss))#for multiple test sample\n",
    "    print('Val Loss x,y,z is %3f, %3f, %3f' %(full_val_loss_x,full_val_loss_y,full_val_loss_z))\n",
    "\n",
    "    writer.add_scalar('Val loss', full_val_loss, epoch)\n",
    "    writer.add_scalar('Val loss x', full_val_loss_x, epoch)\n",
    "    writer.add_scalar('Val loss y', full_val_loss_y, epoch)\n",
    "    writer.add_scalar('Val loss z', full_val_loss_z, epoch)\n",
    "    show2D(xyz.to('cpu').detach(),score.to('cpu').detach(),howmany=10,save_name=None)\n",
    "                  \n",
    "    torch.save(net.state_dict(), os.path.join(log_path, 'model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show2D(xyz.to('cpu').detach(),score.to('cpu').detach(),howmany=10,save_name=log_path+'/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training code for only prediciting orientation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 8 #number of orientation, as classification problem\n",
    "device = torch.device(\"cuda\")\n",
    "net=vgg_bn(config_key='D_4',num_out = num_class,dropout = False,num_hiddenunit=100)\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(net.parameters(),lr=lr)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [3,5,10,20], gamma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "step=0\n",
    "for epoch in range(60):\n",
    "    print(\"Current epoch number%d\" %epoch) \n",
    "    for idx,data in enumerate(train_loader,0):\n",
    "        net.train()\n",
    "        FS,xyz,theta,phi=data['FS'].to(device),data['xyzthetaphi'][:,0:3].to(device),data['xyzthetaphi'][:,3].to(device),data['xyzthetaphi'][:,4].to(device)\n",
    "        score=net(FS)\n",
    "        loss=criterion(score,theta.type(torch.int64))\n",
    "        print('Loss is %3f' %(loss.item()))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            writer.add_scalar('loss', loss.item(), step)\n",
    "        \n",
    "        step = step + 1 \n",
    "        \n",
    "    full_val_loss = 0\n",
    "    full_val_acc = 0\n",
    "    net.eval()\n",
    "    for idx,data in enumerate(val_loader,0):\n",
    "        with torch.no_grad():\n",
    "            FS,xyz,theta,phi=data['FS'].to(device),data['xyzthetaphi'][:,0:3].to(device),data['xyzthetaphi'][:,3].to(device),data['xyzthetaphi'][:,4].to(device)\n",
    "            score=net(FS)\n",
    "            loss=criterion(score,theta.type(torch.int64))\n",
    "            predicted_class = score.cpu().detach().numpy().argmax(1)\n",
    "            val_acc = sum((predicted_class == theta.cpu().detach().numpy()))/len(theta)\n",
    "            full_val_acc += val_acc/len(val_loader) #assume each batch has same number of samples\n",
    "            full_val_loss += loss.item()/len(val_loader)\n",
    "\n",
    "    print('Val Loss is %3f, classification accuracy is %3f' %(full_val_loss,full_val_acc))#for multiple test sample\n",
    "    writer.add_scalar('Val loss', full_val_loss, epoch)\n",
    "    writer.add_scalar('Val classification accuracy', full_val_acc, epoch)\n",
    "     \n",
    "    #save model at the end of every epoch\n",
    "    torch.save(net.state_dict(), os.path.join(log_path, 'model.pth'))\n",
    "    scheduler.step()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

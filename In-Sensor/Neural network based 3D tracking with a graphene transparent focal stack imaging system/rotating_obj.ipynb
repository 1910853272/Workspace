{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Version for Multiple obj points (2 or 3) and multiple shifts, generating a x,y rotating moving object prediction. \n",
    "##### To run: chose proper os.chdir and data_path. chose proper input_dim, and note other hyper settings. Chose desired relative_pos_list. Rest doesn't need to change necessarily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split,Subset\n",
    "from torch.nn.parameter import Parameter\n",
    "from logger import Logger\n",
    "import os\n",
    "from utils_twopoints import *\n",
    "from visualize import show2D_2objs, show2D_3objs, show3Dpred_2objs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(190)\n",
    "torch.manual_seed(120) ##set the random seed so when construct the \n",
    "\n",
    "#os.chdir('E:/Academic/MATLAB/Dehui_FS/2018_11_03 data')\n",
    "#data_path='18_11_03sweepxyz'\n",
    "#os.chdir('E:/Academic/MATLAB/Dehui_FS/2018_11_21 CCD XYZ sweep')\n",
    "#data_path='FS_LD9by9_All_CCD sweep xyz_avg_win20_normalizedbymax'\n",
    "os.chdir('/home/zyhuang/WD/Net3D/2018_11_21 CCD XYZ sweep/')\n",
    "data_path='FS_4by4_CMOS_avg_win20_normalizedbymax'\n",
    "scale_z=True #divide z coord by 33.3 to make it has same range as x,y\n",
    "lr=1e-3\n",
    "num_epoch=2000\n",
    "logfreq=10\n",
    "rotating_idx = [0,1,2,3,0,1,2,3,0,1,2]#rotation\n",
    "num_trajectory = 9*4+2\n",
    "xy_center_idx = []\n",
    "while len(xy_center_idx) < num_trajectory:\n",
    "    x = np.random.randint(low=2,high=9)#  integer in [2,8], only suitable for the current shape of object and spatial grid\n",
    "    y = np.random.randint(low=2,high=9)#  only suitable for the current shape of object and spatial grid\n",
    "    if (x,y) not in xy_center_idx:\n",
    "        xy_center_idx.append((x,y))\n",
    "bs_test=len(rotating_idx)*len(xy_center_idx) #specify test set size\n",
    "bs_train=100\n",
    "num_features=64\n",
    "input_dim=4*4*2\n",
    "#input_dim=32*32*2\n",
    "nx,ny,nz=11,11,11\n",
    "relative_pos_list=[[(0,0,0),(2,4,0)],[(0,0,0),(4,2,0)],[(4,0,0),(0,2,0)],[(2,0,0),(0,4,0)]] #for two objs, four shifts\n",
    "\n",
    "Nshift=len(relative_pos_list)\n",
    "Nobj=len(relative_pos_list[0])\n",
    "\n",
    "#concatenate dataset of different orientation\n",
    "ds_o1 = FSdataset_twopoints_v2(data_path,relative_pos=relative_pos_list[0],nx=nx,ny=ny,nz=nz,scale_z=scale_z)\n",
    "ds_o2 = FSdataset_twopoints_v2(data_path,relative_pos=relative_pos_list[1],nx=nx,ny=ny,nz=nz,scale_z=scale_z)\n",
    "ds_o3 = FSdataset_twopoints_v2(data_path,relative_pos=relative_pos_list[2],nx=nx,ny=ny,nz=nz,scale_z=scale_z)\n",
    "ds_o4 = FSdataset_twopoints_v2(data_path,relative_pos=relative_pos_list[3],nx=nx,ny=ny,nz=nz,scale_z=scale_z)\n",
    "ds_Full = ds_o1+ds_o2+ds_o3+ds_o4\n",
    "\n",
    "test_idx = []\n",
    "#append idx for trajectory at each center location\n",
    "for xy in xy_center_idx:\n",
    "    test_idx.extend(genRotation_data_idx_multi_orientation(xy[0],xy[1],[2,4,4,2],[4,2,2,4],nx=11,ny=11,nz=11,single_orientation_ds_list=[ds_o1,ds_o2,ds_o3,ds_o4],rotating_idx=rotating_idx))\n",
    "# Split train/test set\n",
    "train_idx = np.arange(len(ds_Full)).tolist()\n",
    "for i in test_idx:\n",
    "    train_idx.remove(i)\n",
    "\n",
    "ds_train = Subset(ds_Full,train_idx)\n",
    "ds_test = Subset(ds_Full,test_idx)\n",
    "\n",
    "train_loader=DataLoader(ds_train, batch_size=bs_train,shuffle=True)\n",
    "test_loader=DataLoader(ds_test, batch_size=bs_test,shuffle=False)\n",
    "\n",
    "save_name = '4by4_avg20'+ str(Nobj)+'_objs_singlenetxyz_Set_loss_'+str(Nshift)+'shifts_scale_z_'+str(scale_z)+'/'+\"\".join([s for s in str(relative_pos_list) if s.isdigit()])\\\n",
    "    +'/depthnet4_Nobj_xyz('+str(num_features)+'features)'+'_adam_lr_'+str(lr)+'_bs_train_'+str(bs_train)+'_bs_test_'+str(bs_test)+'_numepoch_'+str(num_epoch)+ '/rot_'\\\n",
    "    + 'num_traj_' + str(num_trajectory)\n",
    "logger = Logger('./logs_paper_data/'+ save_name) ##set the logger for tensorboard and save the log file to ./logs/Adam \n",
    "#dtype = torch.FloatTensor ##run on cpu\n",
    "dtype = torch.cuda.FloatTensor \n",
    "\n",
    "net=depthnet4_Nobj_xyz(input_dim,num_features,Nobj=Nobj)\n",
    "net.type(dtype)\n",
    "\n",
    "\n",
    "criterion=Set_loss_2obj()   \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "36/252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history=[]\n",
    "test_loss_history=[]\n",
    "for epoch in range(num_epoch):\n",
    "    if np.mod(epoch,logfreq)==0: \n",
    "        print(\"Current epoch number%d\" %epoch) \n",
    "    for idx,data in enumerate(train_loader,0):\n",
    "        net.train()\n",
    "        if Nobj == 2:\n",
    "            FS_bat,xyz1_true,xyz2_true=Variable(data['FS'].type(dtype)),Variable(data['xyz'][:,0:3].type(dtype)),Variable(data['xyz'][:,3:6].type(dtype))\n",
    "            xyz1_pred,xyz2_pred=net(FS_bat)[:,0:3],net(FS_bat)[:,3:6]\n",
    "            loss=criterion(xyz1_pred,xyz2_pred,xyz1_true,xyz2_true)\n",
    "        elif Nobj == 3:\n",
    "            FS_bat,xyz1_true,xyz2_true,xyz3_true=Variable(data['FS'].type(dtype)),Variable(data['xyz'][:,0:3].type(dtype)),Variable(data['xyz'][:,3:6].type(dtype)),Variable(data['xyz'][:,6:9].type(dtype))\n",
    "            xyz1_pred,xyz2_pred,xyz3_pred=net(FS_bat)[:,0:3],net(FS_bat)[:,3:6],net(FS_bat)[:,6:9]\n",
    "            loss=criterion(xyz1_pred,xyz2_pred,xyz3_pred,xyz1_true,xyz2_true,xyz3_true)            \n",
    "        loss_history.append(loss.data[0])\n",
    "        if np.mod(epoch,logfreq)==0: \n",
    "            print('loss is %3f'%(loss.data[0]))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if np.mod(epoch,logfreq)==0:  \n",
    "        net.eval()\n",
    "        data=next(iter(test_loader))\n",
    "        if Nobj ==2:\n",
    "            FS_bat,xyz1_true,xyz2_true=Variable(data['FS'].type(dtype)),Variable(data['xyz'][:,0:3].type(dtype)),Variable(data['xyz'][:,3:6].type(dtype))\n",
    "            xyz1_pred,xyz2_pred=net(FS_bat)[:,0:3],net(FS_bat)[:,3:6]\n",
    "            test_loss=criterion(xyz1_pred,xyz2_pred,xyz1_true,xyz2_true)\n",
    "        elif Nobj ==3:\n",
    "            FS_bat,xyz1_true,xyz2_true,xyz3_true=Variable(data['FS'].type(dtype)),Variable(data['xyz'][:,0:3].type(dtype)),Variable(data['xyz'][:,3:6].type(dtype)),Variable(data['xyz'][:,6:9].type(dtype))\n",
    "            xyz1_pred,xyz2_pred,xyz3_pred=net(FS_bat)[:,0:3],net(FS_bat)[:,3:6],net(FS_bat)[:,6:9]\n",
    "            test_loss=criterion(xyz1_pred,xyz2_pred,xyz3_pred,xyz1_true,xyz2_true,xyz3_true)\n",
    "            \n",
    "        test_loss_history.append(test_loss.data[0])       \n",
    "        print('Test Loss is %3f' %(test_loss.data[0]))#for multiple test sample\n",
    "        \n",
    "        step=epoch+1\n",
    "        info = {\n",
    "        'training_loss': loss.data[0],\n",
    "        'val_loss':test_loss.data[0],\n",
    "        }\n",
    "        for tag, value in info.items():\n",
    "            logger.scalar_summary(tag, value, step+1)\n",
    "\n",
    "torch.save(net.state_dict(), os.path.join('logs_paper_data',save_name, 'model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(loss_history[::len(train_loader)],label='training_loss')#training_loss\n",
    "plt.legend()\n",
    "plt.title('Training loss vs epoch number')\n",
    "plt.savefig('logs_paper_data/'+save_name+'/Train loss')\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(0,epoch,logfreq),test_loss_history[:],label='test_loss')\n",
    "plt.legend()\n",
    "plt.title('Test loss vs epoch number')\n",
    "plt.savefig('logs_paper_data/'+save_name+'/Test loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this part of code is added , previsouly the test loss is not the final model test loss since np.mod(epoch,logfreq)==0 is false for last epoch \n",
    "net.eval()\n",
    "\n",
    "data=next(iter(test_loader))\n",
    "if Nobj ==2:\n",
    "    FS_bat,xyz1_true,xyz2_true=Variable(data['FS'].type(dtype)),Variable(data['xyz'][:,0:3].type(dtype)),Variable(data['xyz'][:,3:6].type(dtype))\n",
    "    xyz1_pred,xyz2_pred=net(FS_bat)[:,0:3],net(FS_bat)[:,3:6]\n",
    "    test_loss=criterion(xyz1_pred,xyz2_pred,xyz1_true,xyz2_true)\n",
    "elif Nobj ==3:\n",
    "    FS_bat,xyz1_true,xyz2_true,xyz3_true=Variable(data['FS'].type(dtype)),Variable(data['xyz'][:,0:3].type(dtype)),Variable(data['xyz'][:,3:6].type(dtype)),Variable(data['xyz'][:,6:9].type(dtype))\n",
    "    xyz1_pred,xyz2_pred,xyz3_pred=net(FS_bat)[:,0:3],net(FS_bat)[:,3:6],net(FS_bat)[:,6:9]\n",
    "    test_loss=criterion(xyz1_pred,xyz2_pred,xyz3_pred,xyz1_true,xyz2_true,xyz3_true)\n",
    "text_file = open('logs_paper_data/'+save_name+\"/Loss_final.txt\", \"w\")\n",
    "text_file.write('loss is %.4f(%.3f mm)\\n'%(loss.data[0],np.sqrt(loss.data[0])))\n",
    "text_file.write('Test Loss is %.4f(%.3f mm).' %(test_loss.data[0],np.sqrt(test_loss.data[0])))\n",
    "text_file.close()\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bat=next(iter(test_loader))\n",
    "FS_bat,trueXYZobjs_bat=test_bat['FS'],test_bat['xyz'][:,:]\n",
    "#predXYZobjs_bat=torch.cat((net_x(Variable(FS_bat.type(dtype))),net_y(Variable(FS_bat.type(dtype))),net_z(Variable(FS_bat.type(dtype)))),dim=1).data.cpu()[:,[0,2,4,1,3,5]]\n",
    "predXYZobjs_bat=net(Variable(FS_bat).type(dtype)).data.cpu()\n",
    "print(predXYZobjs_bat)\n",
    "print(trueXYZobjs_bat)\n",
    "globals()['show2D_'+str(Nobj)+'objs'](trueXYZobjs_bat,predXYZobjs_bat,howmany=11,save_name='logs_paper_data/'+save_name+'/2Ds')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib auto\n",
    "show3Dpred_2objs(trueXYZobjs_bat,predXYZobjs_bat,howmany=8,save_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "data={'trueXYZ':trueXYZobjs_bat.cpu().numpy(), 'PredictedXYZ':predXYZobjs_bat.cpu().numpy()}\n",
    "io.savemat('logs_paper_data/'+save_name+\"/testData.mat\",data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Time serialization part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split,Subset\n",
    "from torch.nn.parameter import Parameter\n",
    "from logger import Logger\n",
    "import os\n",
    "from utils_twopoints import *\n",
    "from visualize import show2D_2objs, show2D_3objs, show3Dpred_2objs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(190)\n",
    "torch.manual_seed(120) ##set the random seed so when construct the \n",
    "\n",
    "#os.chdir('E:/Academic/MATLAB/Dehui_FS/2018_11_03 data')\n",
    "#data_path='18_11_03sweepxyz'\n",
    "os.chdir('E:/Academic/MATLAB/Dehui_FS/2018_11_21 CCD XYZ sweep')\n",
    "data_path='FS_LD32by32_All_CCD sweep xyz_avg_win4_normalizedbymax'\n",
    "scale_z=True #divide z coord by 33.3 to make it has same range as x,y\n",
    "rotating_idx = [0,1,2,3,0,1,2,3,0,1,2]#rotation\n",
    "num_trajectory = 9\n",
    "xy_center_idx = []\n",
    "while len(xy_center_idx) < num_trajectory:\n",
    "    x = np.random.randint(low=2,high=9)#  integer in [2,8], only suitable for the current shape of object and spatial grid\n",
    "    y = np.random.randint(low=2,high=9)#  only suitable for the current shape of object and spatial grid\n",
    "    if (x,y) not in xy_center_idx:\n",
    "        xy_center_idx.append((x,y))\n",
    "bs_test=len(rotating_idx)*len(xy_center_idx) #specify test set size\n",
    "bs_train=100\n",
    "num_features=64\n",
    "#input_dim=4*4*2\n",
    "input_dim=32*32*2\n",
    "nx,ny,nz=11,11,11\n",
    "relative_pos_list=[[(0,0,0),(2,4,0)],[(0,0,0),(4,2,0)],[(4,0,0),(0,2,0)],[(2,0,0),(0,4,0)]] #for two objs, four shifts\n",
    "\n",
    "Nshift=len(relative_pos_list)\n",
    "Nobj=len(relative_pos_list[0])\n",
    "\n",
    "#concatenate dataset of different orientation\n",
    "ds_o1 = FSdataset_twopoints_v2(data_path,relative_pos=relative_pos_list[0],nx=nx,ny=ny,nz=nz,scale_z=scale_z)\n",
    "ds_o2 = FSdataset_twopoints_v2(data_path,relative_pos=relative_pos_list[1],nx=nx,ny=ny,nz=nz,scale_z=scale_z)\n",
    "ds_o3 = FSdataset_twopoints_v2(data_path,relative_pos=relative_pos_list[2],nx=nx,ny=ny,nz=nz,scale_z=scale_z)\n",
    "ds_o4 = FSdataset_twopoints_v2(data_path,relative_pos=relative_pos_list[3],nx=nx,ny=ny,nz=nz,scale_z=scale_z)\n",
    "ds_Full = ds_o1+ds_o2+ds_o3+ds_o4\n",
    "\n",
    "test_idx = []\n",
    "#append idx for trajectory at each center location\n",
    "for xy in xy_center_idx:\n",
    "    test_idx.extend(genRotation_data_idx_multi_orientation(xy[0],xy[1],[2,4,4,2],[4,2,2,4],nx=11,ny=11,nz=11,single_orientation_ds_list=[ds_o1,ds_o2,ds_o3,ds_o4],rotating_idx=rotating_idx))\n",
    "# Split train/test set\n",
    "train_idx = np.arange(len(ds_Full)).tolist()\n",
    "for i in test_idx:\n",
    "    train_idx.remove(i)\n",
    "\n",
    "ds_train = Subset(ds_Full,train_idx)\n",
    "ds_test = Subset(ds_Full,test_idx)\n",
    "\n",
    "train_loader=DataLoader(ds_train, batch_size=bs_train,shuffle=True)\n",
    "test_loader=DataLoader(ds_test, batch_size=bs_test,shuffle=False)\n",
    "\n",
    "model_path = 'model.pth'\n",
    "\n",
    "#dtype = torch.FloatTensor ##run on cpu\n",
    "dtype = torch.cuda.FloatTensor \n",
    "\n",
    "net=depthnet4_Nobj_xyz(input_dim,num_features,Nobj=Nobj)\n",
    "net.type(dtype)\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "criterion=Set_loss_2obj()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this part of code is added , previsouly the test loss is not the final model test loss since np.mod(epoch,logfreq)==0 is false for last epoch \n",
    "net.eval()\n",
    "\n",
    "data=next(iter(test_loader))\n",
    "if Nobj ==2:\n",
    "    FS_bat,xyz1_true,xyz2_true=Variable(data['FS'].type(dtype)),Variable(data['xyz'][:,0:3].type(dtype)),Variable(data['xyz'][:,3:6].type(dtype))\n",
    "    xyz1_pred,xyz2_pred=net(FS_bat)[:,0:3],net(FS_bat)[:,3:6]\n",
    "    test_loss=criterion(xyz1_pred,xyz2_pred,xyz1_true,xyz2_true)\n",
    "    print(\"Test loss is %.4f\" %test_loss)\n",
    "elif Nobj ==3:\n",
    "    FS_bat,xyz1_true,xyz2_true,xyz3_true=Variable(data['FS'].type(dtype)),Variable(data['xyz'][:,0:3].type(dtype)),Variable(data['xyz'][:,3:6].type(dtype)),Variable(data['xyz'][:,6:9].type(dtype))\n",
    "    xyz1_pred,xyz2_pred,xyz3_pred=net(FS_bat)[:,0:3],net(FS_bat)[:,3:6],net(FS_bat)[:,6:9]\n",
    "    test_loss=criterion(xyz1_pred,xyz2_pred,xyz3_pred,xyz1_true,xyz2_true,xyz3_true)\n",
    "    print(\"Test loss is %.4f\" %test_loss)\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bat=next(iter(test_loader))\n",
    "FS_bat,trueXYZobjs_bat=test_bat['FS'],test_bat['xyz'][:,:]\n",
    "#predXYZobjs_bat=torch.cat((net_x(Variable(FS_bat.type(dtype))),net_y(Variable(FS_bat.type(dtype))),net_z(Variable(FS_bat.type(dtype)))),dim=1).data.cpu()[:,[0,2,4,1,3,5]]\n",
    "predXYZobjs_bat=net(Variable(FS_bat).type(dtype)).data.cpu()\n",
    "print(predXYZobjs_bat)\n",
    "print(trueXYZobjs_bat)\n",
    "globals()['show2D_'+str(Nobj)+'objs'](trueXYZobjs_bat,predXYZobjs_bat,howmany=11)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib auto\n",
    "show3Dpred_2objs(trueXYZobjs_bat,predXYZobjs_bat,howmany=8,save_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "data={'trueXYZ':trueXYZobjs_bat.cpu().numpy(), 'PredictedXYZ':predXYZobjs_bat.cpu().numpy()}\n",
    "io.savemat('CMOS32by32.mat',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

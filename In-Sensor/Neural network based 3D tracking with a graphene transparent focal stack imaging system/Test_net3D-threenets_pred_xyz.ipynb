{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test time inference using trained model for net3D-threenets_pred_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset as dset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.io import loadmat\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from logger import Logger\n",
    "import os as os\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "torch.backends.cudnn.deterministic=True\n",
    "\n",
    "plt.rcParams.update({'font.size': 15,'lines.markersize':10})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_single_point import *\n",
    "from visualize import *\n",
    "np.random.seed(190)\n",
    "torch.manual_seed(120) ##set the random seed so when construct the \n",
    "#os.chdir('E:/Academic/MATLAB/Dehui_FS/2018_10_24 data')\n",
    "os.chdir('E:/Academic/MATLAB/Dehui_FS/2018_11_03 data')\n",
    "#os.chdir('E:/Academic/MATLAB/Dehui_FS/2018_11_21 CCD XYZ sweep')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_x,lr_y,lr_z=1e-2,1e-2,1e-2\n",
    "bs_train=50\n",
    "bs_test=200\n",
    "num_epoch=2000\n",
    "save_name='Depthnet4_4_3(128_128_32features)_adam_lr_x_'+str(lr_x)+'_lr_y_'+str(lr_y)+'_lr_z_'+str(lr_z)+'_bs_train_'+str(bs_train)+'_bs_test_'+str(bs_test)+'_numepoch_'+str(num_epoch)\n",
    "\n",
    "\"\"\"\n",
    "dataidx:specify what subset of the fulldata is used to split into train/test, \n",
    "e.g, for a particular fixed xy and sweep z,np.arange(0,1999,100)\n",
    "for a particular fixed z and sweep xy, np.arange(100,200,1)\n",
    "test+idx specify among the subset of the fulldata, which point is used as the testset (start from 1, ie, test_idx=1 means FS_all[0] )\n",
    "\"\"\"\n",
    "#data_idx=np.arange(0,396,36)## fixed  particular xy, sweep z \n",
    "#dataidx=np.arange(0,6) ## fixed  particular yï¼Œz, sweep x\n",
    "data_idx=np.arange(0,1331) ##all data used for 3D regression\n",
    "test_idx=(np.random.permutation(np.arange(1331))+1)[:bs_test] ##+1 since test_idx start from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Full_dataset=FSdataset('18_11_03sweepxyz.mat',set='Full',data_idx=data_idx,test_idx=test_idx)\n",
    "\n",
    "train_dataset=FSdataset('18_11_03sweepxyz.mat',set='Train',data_idx=data_idx,test_idx=test_idx)\n",
    "train_loader=DataLoader(train_dataset, batch_size=bs_train,shuffle=True)\n",
    "test_dataset=FSdataset('18_11_03sweepxyz.mat',set='Test',data_idx=data_idx,test_idx=test_idx)\n",
    "test_loader=DataLoader(test_dataset, batch_size=bs_test,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtype = torch.FloatTensor ##run on cpu\n",
    "dtype = torch.cuda.FloatTensor \n",
    "\n",
    "net_x=depthnet4(input_dim=4*4*2,num_features=128)\n",
    "net_y=depthnet4(input_dim=4*4*2,num_features=128)\n",
    "net_z=depthnet3(input_dim=4*4*2,num_features=32)\n",
    "\n",
    "net_x.type(dtype)\n",
    "net_y.type(dtype)\n",
    "net_z.type(dtype)\n",
    "\n",
    "net_x.load_state_dict(torch.load('logs_paper_data/'+save_name+'/model_x.pth'))\n",
    "net_y.load_state_dict(torch.load('logs_paper_data/'+save_name+'/model_y.pth'))\n",
    "net_z.load_state_dict(torch.load('logs_paper_data/'+save_name+'/model_z.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this part of code is added , previsouly the test loss is not the final model test loss since np.mod(epoch,logfreq)==0 is false for last epoch \n",
    "net_x.eval()\n",
    "net_y.eval()\n",
    "net_z.eval()\n",
    "data=next(iter(test_loader))\n",
    "FS_test_bat,trueXobj_test_bat,trueYobj_test_bat,trueZobj_test_bat=data['FS'],data['xyz'][:,0],data['xyz'][:,1],data['xyz'][:,2]\n",
    "estXobj_test,estYobj_test,estZobj_test=net_x(Variable(FS_test_bat.type(dtype))),net_y(Variable(FS_test_bat.type(dtype))),net_z(Variable(FS_test_bat.type(dtype)))\n",
    "\n",
    "\n",
    "test_bat=next(iter(test_loader))\n",
    "FS_bat,trueXYZobj_bat=test_bat['FS'],test_bat['xyz'][:,:]\n",
    "predXYZobj_bat=torch.cat((net_x(Variable(FS_bat.type(dtype))),net_y(Variable(FS_bat.type(dtype))),net_z(Variable(FS_bat.type(dtype)))),dim=1).data.cpu()\n",
    "print(predXYZobj_bat)\n",
    "print(trueXYZobj_bat)\n",
    "\n",
    "\n",
    "show3Dpred(trueXYZobj_bat,predXYZobj_bat,howmany=10,save_name='logs_paper_data/'+save_name+'/3D_new')\n",
    "show2D(trueXYZobj_bat,predXYZobj_bat,howmany=10,save_name='logs_paper_data/'+save_name+'/2Ds_new')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

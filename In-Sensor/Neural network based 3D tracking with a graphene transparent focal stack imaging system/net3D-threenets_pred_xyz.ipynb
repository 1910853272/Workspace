{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Version for single obj using the three separate networks for prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset as dset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.io import loadmat\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from logger import Logger\n",
    "import os as os\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "torch.backends.cudnn.deterministic=True\n",
    "\n",
    "plt.rcParams.update({'font.size': 15,'lines.markersize':10})\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_single_point import *\n",
    "from visualize import *\n",
    "np.random.seed(190)\n",
    "torch.manual_seed(120) ##set the random seed so when construct the \n",
    "#os.chdir('E:/Academic/MATLAB/Dehui_FS/2018_10_24 data')\n",
    "#os.chdir('E:/Academic/MATLAB/Dehui_FS/2018_11_03 data')\n",
    "#os.chdir('E:/Academic/MATLAB/Dehui_FS/2018_11_21 CCD XYZ sweep')\n",
    "os.chdir('/home/zyhuang/WD/Net3D/2018_11_21 CCD XYZ sweep/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfreq=10\n",
    "lr_x,lr_y,lr_z=1e-2,1e-2,1e-2\n",
    "bs_train=50\n",
    "bs_test=200\n",
    "num_epoch=2000\n",
    "dataset_name = 'FS_32by32_CMOS_avg_win1_normalizedbymax'\n",
    "save_name=dataset_name+'/Depthnet4_4_3(128_128_32features)_adam_lr_x_'+str(lr_x)+'_lr_y_'+str(lr_y)+'_lr_z_'+str(lr_z)+'_bs_train_'+str(bs_train)+'_bs_test_'+str(bs_test)+'_numepoch_'+str(num_epoch)\n",
    "logger = Logger('./logs_paper_data/'+ save_name) ##set the logger for tensorboard and save the log file to ./logs/Adam \n",
    "\n",
    "\"\"\"\n",
    "dataidx:specify what subset of the fulldata is used to split into train/test, \n",
    "e.g, for a particular fixed xy and sweep z,np.arange(0,1999,100)\n",
    "for a particular fixed z and sweep xy, np.arange(100,200,1)\n",
    "test+idx specify among the subset of the fulldata, which point is used as the testset (start from 1, ie, test_idx=1 means FS_all[0] )\n",
    "\"\"\"\n",
    "#data_idx=np.arange(0,396,36)## fixed  particular xy, sweep z \n",
    "#dataidx=np.arange(0,6) ## fixed  particular yï¼Œz, sweep x\n",
    "data_idx=np.arange(0,1331) ##all data used for 3D regression\n",
    "test_idx=(np.random.permutation(np.arange(1331))+1)[:bs_test] ##+1 since test_idx start from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Full_dataset=FSdataset(dataset_name+'.mat',set='Full',data_idx=data_idx,test_idx=test_idx)\n",
    "\n",
    "train_dataset=FSdataset(dataset_name+'.mat',set='Train',data_idx=data_idx,test_idx=test_idx)\n",
    "train_loader=DataLoader(train_dataset, batch_size=bs_train,shuffle=True)\n",
    "test_dataset=FSdataset(dataset_name+'.mat',set='Test',data_idx=data_idx,test_idx=test_idx)\n",
    "test_loader=DataLoader(test_dataset, batch_size=bs_test,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtype = torch.FloatTensor ##run on cpu\n",
    "dtype = torch.cuda.FloatTensor \n",
    "\n",
    "net_x=depthnet4(input_dim=32*32*2,num_features=128)\n",
    "net_y=depthnet4(input_dim=32*32*2,num_features=128)\n",
    "net_z=depthnet3(input_dim=32*32*2,num_features=32)\n",
    "\n",
    "net_x.type(dtype)\n",
    "net_y.type(dtype)\n",
    "net_z.type(dtype)\n",
    "\n",
    "#criterion=torch.nn.L1Loss()\n",
    "criterion=torch.nn.MSELoss() #Assignment2 moves this to gpu as well, is it necessary? For MSE loss, no since it has no parameter\n",
    "optimizer_x = torch.optim.Adam(net_x.parameters(), lr=lr_x)\n",
    "optimizer_y = torch.optim.Adam(net_y.parameters(), lr=lr_y)\n",
    "optimizer_z = torch.optim.Adam(net_z.parameters(), lr=lr_z)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_x_history=[]\n",
    "loss_y_history=[]\n",
    "loss_z_history=[]\n",
    "test_loss_x_history=[]\n",
    "test_loss_y_history=[]\n",
    "test_loss_z_history=[]\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    if np.mod(epoch,logfreq)==0: \n",
    "        print(\"Current epoch number%d\" %epoch) \n",
    "\n",
    "    for idx,data in enumerate(train_loader,0):\n",
    "        net_x.train()\n",
    "        net_y.train()\n",
    "        net_z.train()\n",
    "        FS_bat=data['FS']\n",
    "        trueXobj_bat,trueYobj_bat,trueZobj_bat=data['xyz'][:,0],data['xyz'][:,1],data['xyz'][:,2]\n",
    "        FS_bat_var,trueXobj_bat_var,trueYobj_bat_var,trueZobj_bat_var=Variable(FS_bat.type(dtype)),Variable(trueXobj_bat.type(dtype)),Variable(trueYobj_bat.type(dtype)),Variable(trueZobj_bat.type(dtype))\n",
    "        estXobj,estYobj,estZobj=net_x(FS_bat_var),net_y(FS_bat_var),net_z(FS_bat_var)\n",
    "        loss_x,loss_y,loss_z=criterion(estXobj,trueXobj_bat_var),criterion(estYobj,trueYobj_bat_var) ,criterion(estZobj,trueZobj_bat_var)  #the criterion calculate total MSE/Batch size \n",
    "        loss_x_history.append(loss_x.data[0])\n",
    "        loss_y_history.append(loss_y.data[0])\n",
    "        loss_z_history.append(loss_z.data[0])\n",
    "        if np.mod(epoch,logfreq)==0: \n",
    "            print('loss_x is %3f,loss_y is %3f,loss_z is %3f'%(loss_x,loss_y,loss_z))\n",
    "\n",
    "\n",
    "        optimizer_x.zero_grad()\n",
    "        optimizer_y.zero_grad()\n",
    "        optimizer_z.zero_grad()\n",
    "        loss_x.backward()\n",
    "        loss_y.backward()\n",
    "        loss_z.backward()\n",
    "        optimizer_x.step()\n",
    "        optimizer_y.step()\n",
    "        optimizer_z.step()\n",
    "          \n",
    "    \n",
    "    if np.mod(epoch,logfreq)==0:  \n",
    "        net_x.eval()\n",
    "        net_y.eval()\n",
    "        net_z.eval()\n",
    "        data=next(iter(test_loader))\n",
    "        FS_test_bat,trueXobj_test_bat,trueYobj_test_bat,trueZobj_test_bat=data['FS'],data['xyz'][:,0],data['xyz'][:,1],data['xyz'][:,2]\n",
    "        estXobj_test,estYobj_test,estZobj_test=net_x(Variable(FS_test_bat.type(dtype))),net_y(Variable(FS_test_bat.type(dtype))),net_z(Variable(FS_test_bat.type(dtype)))\n",
    "        test_loss_x,test_loss_y,test_loss_z=criterion(estXobj_test,Variable(trueXobj_test_bat.type(dtype))),criterion(estYobj_test,Variable(trueYobj_test_bat.type(dtype))),criterion(estZobj_test,Variable(trueZobj_test_bat.type(dtype)))\n",
    "        \n",
    "        test_loss_x_history.append(test_loss_x.data[0])\n",
    "        test_loss_y_history.append(test_loss_y.data[0])\n",
    "        test_loss_z_history.append(test_loss_z.data[0])\n",
    "        \n",
    "        #print('Test Loss is %3f test prediction is %3f.' %(test_loss.data[0],estZobj_test.data[0]))#for one test sample\n",
    "        print('Test Loss_x is %3f.,Test Loss_y is %3f.,Test Loss_z is %3f.' %(test_loss_x.data[0],test_loss_y.data[0],test_loss_z.data[0]))#for multiple test sample\n",
    "        \n",
    "        step=epoch+1\n",
    "        info = {\n",
    "        'training_loss_x': loss_x.data[0],\n",
    "        'training_loss_y': loss_y.data[0],\n",
    "        'training_loss_z': loss_z.data[0],\n",
    "        'val_loss_x':test_loss_x.data[0],\n",
    "        'val_loss_y':test_loss_y.data[0],\n",
    "        'val_loss_z':test_loss_z.data[0],\n",
    "            \n",
    "        #'Zobj_est':estZobj_test.data[0]##for one test sample\n",
    "            \n",
    "        }\n",
    "   \n",
    "        for tag, value in info.items():\n",
    "            logger.scalar_summary(tag, value, step+1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net_x.state_dict(), os.path.join('logs_paper_data',save_name, 'model_x.pth'))\n",
    "torch.save(net_y.state_dict(), os.path.join('logs_paper_data',save_name, 'model_y.pth'))\n",
    "torch.save(net_z.state_dict(), os.path.join('logs_paper_data',save_name, 'model_z.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(loss_x_history[::len(train_loader)],label='training_loss_x')#training_loss\n",
    "plt.semilogy(loss_y_history[::len(train_loader)],label='training_loss_y')#training_loss\n",
    "plt.semilogy(loss_z_history[::len(train_loader)],label='training_loss_z')#training_loss\n",
    "plt.legend()\n",
    "plt.title('Training loss vs epoch number')\n",
    "plt.savefig('logs_paper_data/'+save_name+'/Training loss')\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(0,epoch,logfreq),test_loss_x_history[:],label='test_loss_x')\n",
    "plt.semilogy(np.arange(0,epoch,logfreq),test_loss_y_history[:],label='test_loss_y')\n",
    "plt.semilogy(np.arange(0,epoch,logfreq),test_loss_z_history[:],label='test_loss_z')\n",
    "plt.legend()\n",
    "plt.title('Test loss vs epoch number')\n",
    "plt.savefig('logs_paper_data/'+save_name+'/Test loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this part of code is added , previsouly the test loss is not the final model test loss since np.mod(epoch,logfreq)==0 is false for last epoch \n",
    "net_x.eval()\n",
    "net_y.eval()\n",
    "net_z.eval()\n",
    "data=next(iter(test_loader))\n",
    "FS_test_bat,trueXobj_test_bat,trueYobj_test_bat,trueZobj_test_bat=data['FS'],data['xyz'][:,0],data['xyz'][:,1],data['xyz'][:,2]\n",
    "estXobj_test,estYobj_test,estZobj_test=net_x(Variable(FS_test_bat.type(dtype))),net_y(Variable(FS_test_bat.type(dtype))),net_z(Variable(FS_test_bat.type(dtype)))\n",
    "test_loss_x,test_loss_y,test_loss_z=criterion(estXobj_test,Variable(trueXobj_test_bat.type(dtype))),criterion(estYobj_test,Variable(trueYobj_test_bat.type(dtype))),criterion(estZobj_test,Variable(trueZobj_test_bat.type(dtype)))\n",
    "##\n",
    "\n",
    "test_bat=next(iter(test_loader))\n",
    "FS_bat,trueXYZobj_bat=test_bat['FS'],test_bat['xyz'][:,:]\n",
    "predXYZobj_bat=torch.cat((net_x(Variable(FS_bat.type(dtype))),net_y(Variable(FS_bat.type(dtype))),net_z(Variable(FS_bat.type(dtype)))),dim=1).data.cpu()\n",
    "print(predXYZobj_bat)\n",
    "print(trueXYZobj_bat)\n",
    "\n",
    "show3Dpred(trueXYZobj_bat,predXYZobj_bat,howmany=10,save_name='logs_paper_data/'+save_name+'/3D')\n",
    "plt.savefig('3d')\n",
    "show2D(trueXYZobj_bat,predXYZobj_bat,howmany=10,save_name='logs_paper_data/'+save_name+'/2Ds')\n",
    "plt.savefig('2d')\n",
    "text_file = open('logs_paper_data/'+save_name+\"/Loss_final.txt\", \"w\")\n",
    "text_file.write('loss_x is %.4f(%.3f mm),loss_y is %.4f(%.3f mm),loss_z is %.4f(%.3f mm)\\n'%(loss_x.data[0],np.sqrt(loss_x.data[0]),loss_y,np.sqrt(loss_y.data[0]),loss_z,np.sqrt(loss_z.data[0])))\n",
    "text_file.write('Test Loss_x is %.4f(%.3f mm).,Test Loss_y is %.4f(%.3f mm).,Test Loss_z is %.4f(%.3f mm).' %(test_loss_x.data[0],np.sqrt(test_loss_x.data[0]),test_loss_y.data[0],np.sqrt(test_loss_y.data[0]),test_loss_z.data[0],np.sqrt(test_loss_z.data[0])))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time benchmark part\n",
    "# res=4\n",
    "# net_x=depthnet4(input_dim=res*res*2,num_features=128)\n",
    "# net_y=depthnet4(input_dim=res*res*2,num_features=128)\n",
    "# net_z=depthnet3(input_dim=res*res*2,num_features=32)\n",
    "\n",
    "# net_x.type(dtype)\n",
    "# net_y.type(dtype)\n",
    "# net_z.type(dtype)\n",
    "# #this part of code is added , previsouly the test loss is not the final model test loss since np.mod(epoch,logfreq)==0 is false for last epoch \n",
    "# net_x.eval()\n",
    "# net_y.eval()\n",
    "# net_z.eval()\n",
    "\n",
    "# test_bat=next(iter(test_loader))\n",
    "# FS_bat=torch.zeros(1,2,res,res)\n",
    "# times = []\n",
    "# for _ in range(500):\n",
    "#     start = torch.cuda.Event(enable_timing=True)\n",
    "#     end = torch.cuda.Event(enable_timing=True)\n",
    "#     start.record()\n",
    "#     with torch.no_grad():\n",
    "#         predXYZobj_bat=torch.cat((net_x(Variable(FS_bat.type(dtype))),net_y(Variable(FS_bat.type(dtype))),net_z(Variable(FS_bat.type(dtype)))),dim=1)\n",
    "#     end.record()\n",
    "#     torch.cuda.synchronize()\n",
    "#     #print(start.elapsed_time(end))\n",
    "#     times.append(start.elapsed_time(end))\n",
    "# print('Mean is {0:.3f}'.format(np.mean(times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open('logs_paper_data/'+save_name+\"/Loss_final.txt\", \"w\")\n",
    "text_file.write('loss_x is %.4f(%.3f mm),loss_y is %.4f(%.3f mm),loss_z is %.4f(%.3f mm)\\n'%(loss_x.data[0],np.sqrt(loss_x.data[0]),loss_y,np.sqrt(loss_y.data[0]),loss_z,np.sqrt(loss_z.data[0])))\n",
    "text_file.write('Test Loss_x is %.4f(%.3f mm).,Test Loss_y is %.4f(%.3f mm).,Test Loss_z is %.4f(%.3f mm).' %(test_loss_x.data[0],np.sqrt(test_loss_x.data[0]),test_loss_y.data[0],np.sqrt(test_loss_y.data[0]),test_loss_z.data[0],np.sqrt(test_loss_z.data[0])))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving test data as .mat\n",
    "from scipy import io\n",
    "data={'trueXYZ':trueXYZobj_bat.cpu().numpy(), 'PredictedXYZ':predXYZobj_bat.cpu().numpy()}\n",
    "io.savemat('logs_paper_data/'+save_name+\"/testData.mat\",data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Training FS')\n",
    "showFS(train_dataset)\n",
    "print('Test FS')\n",
    "showFS(test_dataset)\n",
    "\n",
    "#plot of normalized current vs z for different pixels\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        plt.plot(train_dataset[:]['FS'][:,1,i,j]/train_dataset[:]['FS'][:,1,i,j].sum())\n",
    "plt.title('Plot of normalized current vs Z for each pixel in back plane')\n",
    "plt.show()\n",
    "#plot of normalized current vs z for different pixels\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        plt.plot(train_dataset[:]['FS'][:,0,i,j]/train_dataset[:]['FS'][:,0,i,j].sum())\n",
    "plt.title('Plot of normalized current vs Z for each pixel in front plane')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(net.FC_front.weight.view(4,4).data.abs().cpu())\n",
    "plt.show()\n",
    "plt.plot(train_dataset[:]['FS'][:,0,0,1]/train_dataset[:]['FS'][:,0,0,1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(net.FC_back.weight.view(4,4).data.abs().cpu())\n",
    "plt.show()\n",
    "plt.plot(train_dataset[:]['FS'][:,1,2,2]/train_dataset[:]['FS'][:,1,2,2].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sweep_trace(Full_dataset,Z_idx=10,Y_idx=6,nX=11,nY=11,nZ=11,H=4,W=4)\n",
    "Y_sweep_trace(Full_dataset,Z_idx=10,X_idx=6,nX=11,nY=11,nZ=11,H=4,W=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to test if any test sample is also from train data\n",
    "((test_dataset[:]['xyz'][6]==train_dataset[:]['xyz']).sum(axis=1)==3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
